{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "image = Image.open('messi.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pathlib\n",
    "import subprocess\n",
    "import sys\n",
    "from typing import Callable, Union\n",
    "\n",
    "import dlib\n",
    "import huggingface_hub\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.clamp((tensor + 1) / 2 * 255, 0, 255).to(torch.uint8)\n",
    "def postprocess(tensor: torch.Tensor) -> np.ndarray:\n",
    "        tensor = denormalize(tensor)\n",
    "        return tensor.cpu().numpy().transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.psp import pSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_e4e() -> nn.Module:\n",
    "        ckpt_path = huggingface_hub.hf_hub_download('public-data/e4e',\n",
    "                                                    'e4e_ffhq_encode.pt')\n",
    "        ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "        opts = ckpt['opts']\n",
    "        opts['device'] = \"cpu\"\n",
    "        opts['checkpoint_path'] = ckpt_path\n",
    "        if 'output_size' not in opts:\n",
    "                opts['output_size'] = 1024\n",
    "        print(ckpt_path)\n",
    "        opts = argparse.Namespace(**opts)\n",
    "        model = pSp(opts)\n",
    "        model.to('cpu')\n",
    "        model.eval()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ishant/.cache/huggingface/hub/models--public-data--e4e/snapshots/e1f997577fec5f953f98997ffcc65e4ae00ad2cd/e4e_ffhq_encode.pt\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Encoder4Editing is not a valid encoders",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ishant/Desktop/Computer Vision/textmodulation/re.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ishant/Desktop/Computer%20Vision/textmodulation/re.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m e4e \u001b[39m=\u001b[39m load_e4e()\n",
      "\u001b[1;32m/home/ishant/Desktop/Computer Vision/textmodulation/re.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ishant/Desktop/Computer%20Vision/textmodulation/re.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(ckpt_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ishant/Desktop/Computer%20Vision/textmodulation/re.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m opts \u001b[39m=\u001b[39m argparse\u001b[39m.\u001b[39mNamespace(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopts)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ishant/Desktop/Computer%20Vision/textmodulation/re.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m model \u001b[39m=\u001b[39m pSp(opts)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ishant/Desktop/Computer%20Vision/textmodulation/re.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m model\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ishant/Desktop/Computer%20Vision/textmodulation/re.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/Desktop/Computer Vision/textmodulation/models/psp.py:30\u001b[0m, in \u001b[0;36mpSp.__init__\u001b[0;34m(self, opts)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_opts(opts)\n\u001b[1;32m     27\u001b[0m \u001b[39m# compute number of style inputs based on the output resolution\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39m# self.opts.n_styles = int(math.log(self.opts.output_size, 2)) * 2 - 2\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m# # Define architecture\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_encoder()\n\u001b[1;32m     31\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder \u001b[39m=\u001b[39m Generator(\u001b[39m512\u001b[39m, \u001b[39m512\u001b[39m, \u001b[39m8\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mface_pool \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mAdaptiveAvgPool2d((\u001b[39m256\u001b[39m, \u001b[39m256\u001b[39m))\n",
      "File \u001b[0;32m~/Desktop/Computer Vision/textmodulation/models/psp.py:49\u001b[0m, in \u001b[0;36mpSp.set_encoder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \tencoder \u001b[39m=\u001b[39m psp_encoders\u001b[39m.\u001b[39mBackboneEncoderUsingLastLayerIntoWPlus(\u001b[39m50\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mir_se\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopts)\n\u001b[1;32m     48\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m \t\u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m is not a valid encoders\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopts\u001b[39m.\u001b[39mencoder_type))\n\u001b[1;32m     50\u001b[0m \u001b[39mreturn\u001b[39;00m encoder\n",
      "\u001b[0;31mException\u001b[0m: Encoder4Editing is not a valid encoders"
     ]
    }
   ],
   "source": [
    "e4e = load_e4e()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transform():\n",
    "        transform = T.Compose([\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(256),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "        ])\n",
    "        return transform\n",
    "transform = create_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_face(image: PIL.Image.Image):\n",
    "        input_data = transform(image).unsqueeze(0).to(\"cpu\")\n",
    "        print(input_data.shape)\n",
    "        reconstructed_images, latents = e4e(input_data,\n",
    "                                                 randomize_noise=False,\n",
    "                                                 return_latents=True)\n",
    "        print(reconstructed_images.shape)\n",
    "        print(latents[0].shape)\n",
    "        reconstructed = torch.clamp(reconstructed_images[0].detach(), -1, 1)\n",
    "        reconstructed = postprocess(reconstructed)\n",
    "        return reconstructed, latents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 18, 512])\n",
      "torch.Size([1, 128, 64, 64])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ishant/Desktop/Computer Vision/textmodulation/re.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ishant/Desktop/Computer%20Vision/textmodulation/re.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m r , latent \u001b[39m=\u001b[39m reconstruct_face(image)\n",
      "\u001b[1;32m/home/ishant/Desktop/Computer Vision/textmodulation/re.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ishant/Desktop/Computer%20Vision/textmodulation/re.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(latents[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ishant/Desktop/Computer%20Vision/textmodulation/re.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m reconstructed \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mclamp(reconstructed_images[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdetach(), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ishant/Desktop/Computer%20Vision/textmodulation/re.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m reconstructed \u001b[39m=\u001b[39m postprocess(reconstructed)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ishant/Desktop/Computer%20Vision/textmodulation/re.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mreturn\u001b[39;00m reconstructed, latents[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;32m/home/ishant/Desktop/Computer Vision/textmodulation/re.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ishant/Desktop/Computer%20Vision/textmodulation/re.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpostprocess\u001b[39m(tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ishant/Desktop/Computer%20Vision/textmodulation/re.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         tensor \u001b[39m=\u001b[39m denormalize(tensor)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ishant/Desktop/Computer%20Vision/textmodulation/re.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39;49mtranspose(\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m0\u001b[39;49m)\n",
      "\u001b[0;31mValueError\u001b[0m: axes don't match array"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "r , latent = reconstruct_face(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%wget` not found.\n"
     ]
    }
   ],
   "source": [
    "%wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
